
from sklearn.experimental import enable_iterative_imputer  # æ˜¾å¼å¯ç”¨ IterativeImputer
from sklearn.impute import IterativeImputer
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import torch
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score
import webbrowser
import time

# è®¾ç½® Streamlit é¡µé¢é…ç½®
st.set_page_config(page_title="æ·±åº¦å­¦ä¹ æ•°æ®å¤„ç† App", layout="wide")
st.title("ğŸ§  æ·±åº¦å­¦ä¹ æ•°æ®é¢„å¤„ç†ä¸è¯„ä¼°å¹³å°")

# ä¸Šä¼ æ•°æ®
uploaded_file = st.file_uploader("ğŸ“ ä¸Šä¼ ä½ çš„ CSV æ•°æ®", type=["csv"])
if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.write("### åŸå§‹æ•°æ®é¢„è§ˆ", df.head())

    # è§£å†³æ—¥æœŸåˆ—é—®é¢˜
    # å‡è®¾ 'date_column' æ˜¯æ—¥æœŸåˆ—
    if 'date_column' in df.columns:
        # å°†æ—¥æœŸåˆ—è½¬æ¢ä¸º datetime ç±»å‹
        df['date_column'] = pd.to_datetime(df['date_column'])
        
        # æ–¹æ³•ä¸€ï¼šå°†æ—¥æœŸåˆ—è½¬æ¢ä¸ºæ—¶é—´æˆ³ï¼ˆç§’ï¼‰
        df['date_timestamp'] = df['date_column'].astype(int) / 10**9  # è½¬æ¢ä¸ºæ—¶é—´æˆ³ï¼ˆç§’ï¼‰
        
        # æˆ–è€…æ–¹æ³•äºŒï¼šæå–æ—¥æœŸç‰¹å¾ï¼ˆå¹´ã€æœˆã€æ—¥ã€æ˜ŸæœŸå‡ ç­‰ï¼‰
        df['year'] = df['date_column'].dt.year
        df['month'] = df['date_column'].dt.month
        df['day'] = df['date_column'].dt.day
        df['weekday'] = df['date_column'].dt.weekday
        df['hour'] = df['date_column'].dt.hour
        
        # åˆ é™¤åŸå§‹æ—¥æœŸåˆ—
        df = df.drop(columns=['date_column'])
    
    # ç¼ºå¤±å€¼æ’è¡¥ä¸æ ‡å‡†åŒ–
    st.subheader("ğŸ”§ æ•°æ®æ’è¡¥ä¸æ ‡å‡†åŒ–")
    imputer = IterativeImputer(random_state=0)
    scaler = StandardScaler()

    # æ‰§è¡Œæ’è¡¥å’Œæ ‡å‡†åŒ–
    imputed_data = imputer.fit_transform(df)
    scaled_data = scaler.fit_transform(imputed_data)

    # åˆ›å»ºæ’è¡¥åçš„æ•°æ®æ¡†
    df_imputed = pd.DataFrame(imputed_data, columns=df.columns)
    st.write("### æ’è¡¥åçš„æ•°æ®", df_imputed.head())

    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    from sklearn.model_selection import train_test_split
    X_train, X_test = train_test_split(scaled_data, test_size=0.2, random_state=42)

    # æ„å»º PyTorch æ•°æ®é›†
    class CustomDataset(Dataset):
        def __init__(self, data):
            self.data = torch.tensor(data, dtype=torch.float32)

        def __len__(self):
            return len(self.data)

        def __getitem__(self, idx):
            return self.data[idx]

    train_loader = DataLoader(CustomDataset(X_train), batch_size=32, shuffle=True)

    st.success("æ•°æ®å·²æ’è¡¥ã€æ ‡å‡†åŒ–ï¼Œå¹¶å‡†å¤‡å¥½ç”¨äºæ¨¡å‹è®­ç»ƒã€‚")

    # ç¤ºä¾‹æ¨¡å‹ï¼ˆç®€å•çš„è‡ªç¼–ç å™¨ï¼‰
    st.subheader("ğŸ“‰ æ¨¡å‹è®­ç»ƒç¤ºä¾‹")

    class AutoEncoder(torch.nn.Module):
        def __init__(self, input_dim):
            super(AutoEncoder, self).__init__()
            self.encoder = torch.nn.Linear(input_dim, 8)
            self.decoder = torch.nn.Linear(8, input_dim)

        def forward(self, x):
            x = torch.relu(self.encoder(x))
            x = self.decoder(x)
            return x

    model = AutoEncoder(input_dim=X_train.shape[1])
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    loss_fn = torch.nn.MSELoss()

    num_epochs = st.slider("è®­ç»ƒè½®æ•°", 1, 100, 10)
    losses = []

    progress = st.progress(0, text="æ¨¡å‹è®­ç»ƒä¸­...")
    for epoch in range(num_epochs):
        for batch in train_loader:
            optimizer.zero_grad()
            output = model(batch)
            loss = loss_fn(output, batch)
            loss.backward()
            optimizer.step()
        losses.append(loss.item())
        progress.progress((epoch+1)/num_epochs, text=f"ç¬¬ {epoch+1} / {num_epochs} è½®")

    st.line_chart(losses)

    # æ¨¡å‹è¯„ä¼°
    st.subheader("ğŸ“Š æ¨¡å‹è¯„ä¼°")
    with torch.no_grad():
        preds = model(torch.tensor(X_test, dtype=torch.float32)).numpy()

    def get_result(y_true, y_pred):
        return {
            "MAE": mean_absolute_error(y_true, y_pred),
            "MSE": mean_squared_error(y_true, y_pred),
            "MAPE": mean_absolute_percentage_error(y_true, y_pred),
            "R2": r2_score(y_true, y_pred),
        }

    result = get_result(X_test, preds)
    st.write(pd.DataFrame([result]))

    # å¼ºåˆ¶æ‰“å¼€æµè§ˆå™¨
    time.sleep(1)  # ç­‰å¾…ä¸€ä¼šå„¿ï¼Œç¡®ä¿åº”ç”¨å¯åŠ¨
    webbrowser.open('http://localhost:8501')  # å¼ºåˆ¶æ‰“å¼€æµè§ˆå™¨
