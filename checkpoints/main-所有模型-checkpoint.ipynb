{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "591e6d84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn import impute\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bf047b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(test_true_1array, test_pred_1array):\n",
    "    \"\"\"\n",
    "    评估函数\n",
    "    \"\"\"\n",
    "    mae=metrics.mean_absolute_error(test_true_1array, test_pred_1array)\n",
    "    mse=metrics.mean_squared_error(test_true_1array, test_pred_1array)\n",
    "    mape=metrics.mean_absolute_percentage_error(test_true_1array, test_pred_1array)\n",
    "    r2=metrics.r2_score(test_true_1array, test_pred_1array)\n",
    "    return [mae,mse,mape,r2]\n",
    "\n",
    "result_dict={}\n",
    "predict_dict={}\n",
    "mask_pred_dict={}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c61bd7",
   "metadata": {},
   "source": [
    "# 1、生成掩码数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb167598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16、代表年数据 - 副本.xlsx\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)#固定随机数\n",
    "mask_rate=0.5#===========================掩码率===================\n",
    "file_path=os.listdir('./data')\n",
    "for data_name in file_path:\n",
    "    print(data_name)\n",
    "    data=pd.read_excel(f'./data/{data_name}',index_col=0)#------------读取数据\n",
    "    #-------------引入缺失值\n",
    "    df_missing = data.mask(np.random.random(data.shape) < mask_rate)\n",
    "    df_missing.to_excel(f'./mask_data/{data_name}')#保存代码文件\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6376d4f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#----------设置处理的文件----------\n",
    "data_name=file_path[0]\n",
    "df_missing=pd.read_excel(f'./mask_data/{data_name}',index_col=0)#读取处理的数据对象\n",
    "data=pd.read_excel(f'./data/{data_name}',index_col=0)#------------读取数据\n",
    "\n",
    "#----------提取时间信息--------------\n",
    "df_stamp=df_missing.copy()\n",
    "df_stamp['date']=pd.to_datetime(df_stamp.index)\n",
    "df_stamp=df_stamp[['date']]\n",
    "df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
    "df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
    "df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
    "df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
    "\n",
    "# data_stamp = df_stamp.drop(['date'], 1).values\n",
    "\n",
    "del df_stamp['date']\n",
    "data_stamp = df_stamp.values\n",
    "\n",
    "#------------数据划分-------------\n",
    "train_miss,test_miss,train_data,test_data,train_stamp,test_stamp=train_test_split(df_missing,\n",
    "                                                                                  data,data_stamp,\n",
    "                                                                                  train_size=0.7,shuffle=False)#数据集划分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61011a7b",
   "metadata": {},
   "source": [
    "# 2、MICE插值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4d7b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化 MICE 计算器\n",
    "mice_imputer = impute.IterativeImputer(max_iter=10, random_state=42)\n",
    " \n",
    "# 拟合和转换数据集以填补缺失值\n",
    "mice_imputer.fit(train_miss)\n",
    "train_imputed = mice_imputer.transform(train_miss)\n",
    "start_time=time.time()\n",
    "test_imputed = mice_imputer.transform(test_miss)\n",
    "end_time=time.time()\n",
    "train_true_1array=train_data.values[np.isnan(train_miss)]#缺失处的真实值\n",
    "train_pred_1array=train_imputed[np.isnan(train_miss)]#缺失处的真实值\n",
    "test_true_1array=test_data.values[np.isnan(test_miss)]#缺失处的真实值\n",
    "test_pred_1array=test_imputed[np.isnan(test_miss)]#缺失处的真实值\n",
    "\n",
    "# 计算评估指标\n",
    "mice_result=get_result(test_true_1array, test_pred_1array)+[end_time-start_time]\n",
    "result_dict['MICE']=mice_result\n",
    "predict_dict['MICE']={'true':test_true_1array,'pred':test_pred_1array}\n",
    "\n",
    "test_imputed_df=pd.DataFrame(test_imputed,index=test_miss.index,columns=test_miss.columns)\n",
    "true_mask_df=test_data.mask(test_miss.isna()==False)\n",
    "pred_mask_df=test_imputed_df.mask(test_miss.isna()==False)\n",
    "mask_pred_dict['MICE']={'true':true_mask_df,'pred':pred_mask_df}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d53a60",
   "metadata": {},
   "source": [
    "# 3、KNNI插值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eaf2ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化 MICE 计算器\n",
    "knni_imputer = impute.KNNImputer(n_neighbors=10)\n",
    "\n",
    "knni_imputer.fit(train_miss)\n",
    "train_imputed = knni_imputer.transform(train_miss)\n",
    "start_time=time.time()\n",
    "test_imputed = knni_imputer.transform(test_miss)\n",
    "end_time=time.time()\n",
    "train_true_1array=train_data.values[np.isnan(train_miss)]#缺失处的真实值\n",
    "train_pred_1array=train_imputed[np.isnan(train_miss)]#缺失处的真实值\n",
    "test_true_1array=test_data.values[np.isnan(test_miss)]#缺失处的真实值\n",
    "test_pred_1array=test_imputed[np.isnan(test_miss)]#缺失处的真实值\n",
    "\n",
    "\n",
    "# 计算评估指标\n",
    "knni_result=get_result(test_true_1array, test_pred_1array)+[end_time-start_time]\n",
    "result_dict['KNNI']=knni_result\n",
    "predict_dict['KNNI']={'true':test_true_1array,'pred':test_pred_1array}\n",
    "\n",
    "test_imputed_df=pd.DataFrame(test_imputed,index=test_miss.index,columns=test_miss.columns)\n",
    "true_mask_df=test_data.mask(test_miss.isna()==False)\n",
    "pred_mask_df=test_imputed_df.mask(test_miss.isna()==False)\n",
    "mask_pred_dict['KNNI']={'true':true_mask_df,'pred':pred_mask_df}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3066b8b6",
   "metadata": {},
   "source": [
    "# 4、SimpleImputer插值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8307fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "simp_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "simp_imputer.fit(train_miss)\n",
    "train_imputed = simp_imputer.transform(train_miss)\n",
    "start_time=time.time()\n",
    "test_imputed = simp_imputer.transform(test_miss)\n",
    "end_time=time.time()\n",
    "\n",
    "train_true_1array=train_data.values[np.isnan(train_miss)]#缺失处的真实值\n",
    "train_pred_1array=train_imputed[np.isnan(train_miss)]#缺失处的真实值\n",
    "test_true_1array=test_data.values[np.isnan(test_miss)]#缺失处的真实值\n",
    "test_pred_1array=test_imputed[np.isnan(test_miss)]#缺失处的真实值\n",
    "\n",
    "# 计算评估指标\n",
    "simp_result=get_result(test_true_1array, test_pred_1array)+[end_time-start_time]\n",
    "result_dict['SimpleImputer']=simp_result\n",
    "predict_dict['SimpleImputer']={'true':test_true_1array,'pred':test_pred_1array}\n",
    "\n",
    "test_imputed_df=pd.DataFrame(test_imputed,index=test_miss.index,columns=test_miss.columns)\n",
    "true_mask_df=test_data.mask(test_miss.isna()==False)\n",
    "pred_mask_df=test_imputed_df.mask(test_miss.isna()==False)\n",
    "mask_pred_dict['SimpleImputer']={'true':true_mask_df,'pred':pred_mask_df}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4ad652",
   "metadata": {},
   "source": [
    "# 5、线性插值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a24eb63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_imputed=train_miss.interpolate(method='linear',limit_direction='both')\n",
    "start_time=time.time()\n",
    "test_imputed=test_miss.interpolate(method='linear',limit_direction='both')\n",
    "end_time=time.time()\n",
    "\n",
    "train_true_1array=train_data.values[np.isnan(train_miss)]#缺失处的真实值\n",
    "train_pred_1array=train_imputed[np.isnan(train_miss)]#缺失处的真实值\n",
    "test_true_1array=test_data.values[np.isnan(test_miss)]#缺失处的真实值\n",
    "test_pred_1array=test_imputed.values[np.isnan(test_miss)]#缺失处的真实值\n",
    "\n",
    "# 计算评估指标\n",
    "line_result=get_result(test_true_1array, test_pred_1array)+[end_time-start_time]\n",
    "result_dict['Linear']=line_result\n",
    "predict_dict['Linear']={'true':test_true_1array,'pred':test_pred_1array}\n",
    "\n",
    "test_imputed_df=pd.DataFrame(test_imputed,index=test_miss.index,columns=test_miss.columns)\n",
    "true_mask_df=test_data.mask(test_miss.isna()==False)\n",
    "pred_mask_df=test_imputed_df.mask(test_miss.isna()==False)\n",
    "mask_pred_dict['Linear']={'true':true_mask_df,'pred':pred_mask_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe96eca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75b93d67",
   "metadata": {},
   "source": [
    "# 6、深度学习模型插值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1eea9b",
   "metadata": {},
   "source": [
    "# 6.1、Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53385cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_debatch_data(preds):\n",
    "    \"\"\"\n",
    "    预测的数据是由batch生成的，导致不同batch之间有重叠，需要消除这个重叠的影响\n",
    "    \"\"\"\n",
    "    windows_size=preds.shape[1]\n",
    "    all_new_df=pd.DataFrame()\n",
    "    for num,i in enumerate(preds):\n",
    "        i_df=pd.DataFrame(i,index=range(num,num+windows_size))\n",
    "        i_df=i_df.loc[list(set(i_df.index)-set(all_new_df.index))]#找到i_dfyou ,all_new_df没有的行\n",
    "        i_df=i_df.sort_index()\n",
    "        all_new_df=pd.concat([all_new_df,i_df])\n",
    "    return all_new_df.values\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from layers.Transformer_EncDec import Decoder, DecoderLayer, Encoder, EncoderLayer, ConvLayer\n",
    "from layers.SelfAttention_Family import FullAttention, AttentionLayer\n",
    "from layers.Embed import DataEmbedding\n",
    "import numpy as np\n",
    "\n",
    "# from data_provider.data_factory import data_provider\n",
    "# from exp.exp_basic import Exp_Basic\n",
    "from utils.tools import EarlyStopping, adjust_learning_rate, visual\n",
    "from utils.metrics import metric\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "from torch import optim\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "# import numpy as np\n",
    "import argparse\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(Model, self).__init__()\n",
    "        # Embedding\n",
    "        self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
    "                                           configs.dropout)\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(False, configs.factor, attention_dropout=configs.dropout,\n",
    "                                      output_attention=configs.output_attention), configs.d_model, configs.n_heads),\n",
    "                    configs.d_model,\n",
    "                    configs.d_ff,\n",
    "                    dropout=configs.dropout,\n",
    "                    activation=configs.activation\n",
    "                ) for l in range(configs.e_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(configs.d_model)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.projection = nn.Linear(configs.d_model, configs.c_out, bias=True)\n",
    "\n",
    "    def imputation(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask):\n",
    "        # Embedding\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
    "        enc_out, attns = self.encoder(enc_out, attn_mask=None)\n",
    "\n",
    "        dec_out = self.projection(enc_out)\n",
    "        return dec_out\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask=None):\n",
    "        dec_out = self.imputation(x_enc, x_mark_enc, x_dec, x_mark_dec, mask)\n",
    "        return dec_out  # [B, L, D]\n",
    "    \n",
    "class Exp_Imputation():\n",
    "    def __init__(self, args,train_loader,test_loader,model=None):\n",
    "        #super(Exp_Imputation, self).__init__(args)\n",
    "        self.test_loader=test_loader\n",
    "        self.train_loader=train_loader\n",
    "        self.args=args\n",
    "        \n",
    "        self.device=torch.device('cuda' if args.use_gpu else 'cpu')\n",
    "        \n",
    "        if model is None:\n",
    "            self.model=Model(self.args).to(self.device)\n",
    "        else:\n",
    "            self.model=model.to(self.device)\n",
    "        \n",
    "    def _select_optimizer(self):\n",
    "        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n",
    "        return model_optim\n",
    "\n",
    "    def _select_criterion(self):\n",
    "        criterion = nn.MSELoss()\n",
    "        return criterion\n",
    "    \n",
    "    def vali(self, test_loader, criterion):\n",
    "        total_loss = []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x_mask, batch_x, batch_x_mark) in enumerate(test_loader):\n",
    "                batch_x=batch_x.float().to(device)\n",
    "                batch_x_mark = batch_x_mark.float().to(device)\n",
    "                mask=(batch_x_mask.isnan()==False).int().to(device)\n",
    "                batch_x_mask[batch_x_mask.isnan()]=0.0#---------------用0填充缺失值----\n",
    "                batch_x_mask=batch_x_mask.to(torch.float32).to(device)\n",
    "                \n",
    "                outputs = self.model(batch_x_mask, batch_x_mark, None, None, mask)\n",
    "                pred = outputs.detach().cpu()\n",
    "                true = batch_x.detach().cpu()\n",
    "                mask = mask.detach().cpu()\n",
    "                \n",
    "                loss = criterion(pred[mask == 0], true[mask == 0])\n",
    "                total_loss.append(loss.item())\n",
    "        total_loss = np.average(total_loss)\n",
    "        self.model.train()\n",
    "        return total_loss\n",
    "            \n",
    "    \n",
    "    def train(self, setting):\n",
    "        time_now = time.time()\n",
    "        train_steps = len(self.train_loader)\n",
    "        early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "        model_optim = self._select_optimizer()\n",
    "        criterion = self._select_criterion()\n",
    "        \n",
    "        path = os.path.join('./result/', setting)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        \n",
    "        self.loss_dict={}\n",
    "        self.best_loss=np.inf\n",
    "        for epoch in range(self.args.train_epochs):\n",
    "            iter_count = 0\n",
    "            train_loss = []\n",
    "            self.model.train()\n",
    "            \n",
    "            epoch_time = time.time()\n",
    "            for i, (batch_x_mask, batch_x, batch_x_mark) in enumerate(self.train_loader):\n",
    "                iter_count += 1\n",
    "                model_optim.zero_grad()                \n",
    "                \n",
    "                batch_x=batch_x.float().to(device)\n",
    "                batch_x_mark = batch_x_mark.float().to(device)\n",
    "                mask=(batch_x_mask.isnan()==False).int().to(device)\n",
    "                batch_x_mask[batch_x_mask.isnan()]=0.0#---------------用0填充缺失值----\n",
    "                batch_x_mask=batch_x_mask.to(torch.float32).to(device)\n",
    "                \n",
    "                outputs = self.model(batch_x_mask, batch_x_mark, None, None, mask)\n",
    "                \n",
    "                loss = criterion(outputs[mask == 0], batch_x[mask == 0])\n",
    "                train_loss.append(loss.item())\n",
    "                \n",
    "                if (i + 1) % 100 == 0:\n",
    "                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "                    speed = (time.time() - time_now) / iter_count\n",
    "                    left_time = speed * ((self.args.train_epochs - epoch) * train_steps - i)\n",
    "                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "                    iter_count = 0\n",
    "                    time_now = time.time()\n",
    "\n",
    "                loss.backward()\n",
    "                model_optim.step()\n",
    "                \n",
    "            print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
    "            train_loss = np.average(train_loss)\n",
    "            \n",
    "            test_loss = self.vali(self.test_loader, criterion)\n",
    "            \n",
    "            self.loss_dict[epoch]=[train_loss,test_loss]\n",
    "            \n",
    "            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f}  Test Loss: {3:.7f}\".format(\n",
    "                epoch + 1, train_steps, train_loss, test_loss))\n",
    "            early_stopping(test_loss, self.model, path)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "            adjust_learning_rate(model_optim, epoch + 1, self.args)\n",
    "            \n",
    "            if self.best_loss>test_loss:\n",
    "                best_model_path = path + '/' + 'checkpoint.pth'\n",
    "                torch.save(self.model.state_dict(), best_model_path)\n",
    "                self.best_model_path=best_model_path\n",
    "                #self.model.load_state_dict(torch.load(best_model_path))\n",
    "        \n",
    "    def test(self, setting, test=0):\n",
    "        if test:\n",
    "            print('loading model')\n",
    "            self.model.load_state_dict(torch.load(self.best_model_path))\n",
    "            \n",
    "        preds = []\n",
    "        trues = []\n",
    "        masks = []\n",
    "        \n",
    "        folder_path = './test_results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "            \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x_mask, batch_x, batch_x_mark) in enumerate(test_loader):\n",
    "                batch_x=batch_x.float().to(device)\n",
    "                batch_x_mark = batch_x_mark.float().to(device)\n",
    "                mask=(batch_x_mask.isnan()==False).int().to(device)\n",
    "                batch_x_mask[batch_x_mask.isnan()]=0.0#---------------用0填充缺失值----\n",
    "                batch_x_mask=batch_x_mask.to(torch.float32).to(device)\n",
    "                \n",
    "                outputs = self.model(batch_x_mask, batch_x_mark, None, None, mask)\n",
    "                \n",
    "                outputs = outputs.detach().cpu().numpy()\n",
    "                pred = outputs\n",
    "                true = batch_x.detach().cpu().numpy()\n",
    "                preds.append(pred)\n",
    "                trues.append(true)\n",
    "                masks.append(mask.detach().cpu().numpy())\n",
    "                \n",
    "                if i % 20 == 0:\n",
    "                    filled = true[0, :, -1].copy()\n",
    "                    filled = filled * mask[0, :, -1].detach().cpu().numpy() + \\\n",
    "                             pred[0, :, -1] * (1 - mask[0, :, -1].detach().cpu().numpy())\n",
    "                    visual(true[0, :, -1], filled, os.path.join(folder_path, str(i) + '.pdf'))\n",
    "\n",
    "        preds = np.concatenate(preds, 0)\n",
    "        trues = np.concatenate(trues, 0)\n",
    "        masks = np.concatenate(masks, 0)\n",
    "        print('test shape:', preds.shape, trues.shape)\n",
    "\n",
    "        # result save\n",
    "        folder_path = './results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        mae, mse, rmse, mape, mspe = metric(preds[masks == 0], trues[masks == 0])\n",
    "\n",
    "        print('mse:{}, mae:{}'.format(mse, mae))\n",
    "        f = open(\"result_imputation.txt\", 'a')\n",
    "        f.write(setting + \"  \\n\")\n",
    "        f.write('mse:{}, mae:{}'.format(mse, mae))\n",
    "        f.write('\\n')\n",
    "        f.write('\\n')\n",
    "        f.close()\n",
    "\n",
    "        np.save(folder_path + 'metrics.npy', np.array([mae, mse, rmse, mape, mspe]))\n",
    "        np.save(folder_path + 'pred.npy', preds)\n",
    "        np.save(folder_path + 'true.npy', trues)\n",
    "        return preds,trues,masks\n",
    "\n",
    "\n",
    "class Dataset_me(Dataset):\n",
    "    def __init__(self,miss_data,full_data,date,windows_size=96):\n",
    "        super(Dataset_me,self).__init__()\n",
    "        self.miss_data=miss_data\n",
    "        self.full_data=full_data\n",
    "        self.date=date\n",
    "        self.windows_size=windows_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.miss_data) - self.windows_size + 1\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.windows_size\n",
    "        \n",
    "        seq_miss=self.miss_data[s_begin:s_end]#带有mask的数据\n",
    "        seq_full=self.full_data[s_begin:s_end]#完整的数据\n",
    "        seq_date=self.date[s_begin:s_end]#时间信息\n",
    "        return torch.FloatTensor(seq_miss),torch.FloatTensor(seq_full),torch.FloatTensor(seq_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d42a59-65d2-46fc-938b-f3076df6c9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b686995-6c59-4ed8-b65f-4a8aedf833e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeebe1f4-2e48-4561-92ab-c7f53f95b22e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6140ed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost time: 3.3104100227355957\n",
      "Epoch: 1, Steps: 48 | Train Loss: 1.0391156  Test Loss: 1.4832276\n",
      "Validation loss decreased (inf --> 1.483228).  Saving model ...\n",
      "Updating learning rate to 0.001\n",
      "Epoch: 2 cost time: 2.7999377250671387\n",
      "Epoch: 2, Steps: 48 | Train Loss: 0.6968239  Test Loss: 1.3600604\n",
      "Validation loss decreased (1.483228 --> 1.360060).  Saving model ...\n",
      "Updating learning rate to 0.0005\n",
      "Epoch: 3 cost time: 2.8275134563446045\n",
      "Epoch: 3, Steps: 48 | Train Loss: 0.6311453  Test Loss: 0.5401893\n",
      "Validation loss decreased (1.360060 --> 0.540189).  Saving model ...\n",
      "Updating learning rate to 0.00025\n",
      "Epoch: 4 cost time: 2.8958332538604736\n",
      "Epoch: 4, Steps: 48 | Train Loss: 0.5106380  Test Loss: 0.3605473\n",
      "Validation loss decreased (0.540189 --> 0.360547).  Saving model ...\n",
      "Updating learning rate to 0.000125\n",
      "Epoch: 5 cost time: 2.8622918128967285\n",
      "Epoch: 5, Steps: 48 | Train Loss: 0.4604556  Test Loss: 0.3255971\n",
      "Validation loss decreased (0.360547 --> 0.325597).  Saving model ...\n",
      "Updating learning rate to 6.25e-05\n",
      "Epoch: 6 cost time: 2.84470796585083\n",
      "Epoch: 6, Steps: 48 | Train Loss: 0.4220815  Test Loss: 0.3074570\n",
      "Validation loss decreased (0.325597 --> 0.307457).  Saving model ...\n",
      "Updating learning rate to 3.125e-05\n",
      "Epoch: 7 cost time: 2.7974302768707275\n",
      "Epoch: 7, Steps: 48 | Train Loss: 0.3924252  Test Loss: 0.2916205\n",
      "Validation loss decreased (0.307457 --> 0.291620).  Saving model ...\n",
      "Updating learning rate to 1.5625e-05\n",
      "Epoch: 8 cost time: 2.8053016662597656\n",
      "Epoch: 8, Steps: 48 | Train Loss: 0.3800224  Test Loss: 0.2859482\n",
      "Validation loss decreased (0.291620 --> 0.285948).  Saving model ...\n",
      "Updating learning rate to 7.8125e-06\n",
      "Epoch: 9 cost time: 2.7899928092956543\n",
      "Epoch: 9, Steps: 48 | Train Loss: 0.3742884  Test Loss: 0.2832585\n",
      "Validation loss decreased (0.285948 --> 0.283259).  Saving model ...\n",
      "Updating learning rate to 3.90625e-06\n",
      "Epoch: 10 cost time: 2.819204330444336\n",
      "Epoch: 10, Steps: 48 | Train Loss: 0.3710214  Test Loss: 0.2819022\n",
      "Validation loss decreased (0.283259 --> 0.281902).  Saving model ...\n",
      "Updating learning rate to 1.953125e-06\n",
      "Epoch: 11 cost time: 2.8677549362182617\n",
      "Epoch: 11, Steps: 48 | Train Loss: 0.3699075  Test Loss: 0.2812351\n",
      "Validation loss decreased (0.281902 --> 0.281235).  Saving model ...\n",
      "Updating learning rate to 9.765625e-07\n",
      "Epoch: 12 cost time: 2.875903367996216\n",
      "Epoch: 12, Steps: 48 | Train Loss: 0.3693177  Test Loss: 0.2808954\n",
      "Validation loss decreased (0.281235 --> 0.280895).  Saving model ...\n",
      "Updating learning rate to 4.8828125e-07\n",
      "Epoch: 13 cost time: 2.821491003036499\n",
      "Epoch: 13, Steps: 48 | Train Loss: 0.3686970  Test Loss: 0.2807182\n",
      "Validation loss decreased (0.280895 --> 0.280718).  Saving model ...\n",
      "Updating learning rate to 2.44140625e-07\n",
      "Epoch: 14 cost time: 2.8306732177734375\n",
      "Epoch: 14, Steps: 48 | Train Loss: 0.3685663  Test Loss: 0.2806303\n",
      "Validation loss decreased (0.280718 --> 0.280630).  Saving model ...\n",
      "Updating learning rate to 1.220703125e-07\n",
      "Epoch: 15 cost time: 2.9475855827331543\n",
      "Epoch: 15, Steps: 48 | Train Loss: 0.3685845  Test Loss: 0.2805843\n",
      "Validation loss decreased (0.280630 --> 0.280584).  Saving model ...\n",
      "Updating learning rate to 6.103515625e-08\n",
      "Epoch: 16 cost time: 2.954686164855957\n",
      "Epoch: 16, Steps: 48 | Train Loss: 0.3686357  Test Loss: 0.2805636\n",
      "Validation loss decreased (0.280584 --> 0.280564).  Saving model ...\n",
      "Updating learning rate to 3.0517578125e-08\n",
      "Epoch: 17 cost time: 2.8904528617858887\n",
      "Epoch: 17, Steps: 48 | Train Loss: 0.3685910  Test Loss: 0.2805524\n",
      "Validation loss decreased (0.280564 --> 0.280552).  Saving model ...\n",
      "Updating learning rate to 1.52587890625e-08\n",
      "Epoch: 18 cost time: 2.9085633754730225\n",
      "Epoch: 18, Steps: 48 | Train Loss: 0.3685935  Test Loss: 0.2805475\n",
      "Validation loss decreased (0.280552 --> 0.280547).  Saving model ...\n",
      "Updating learning rate to 7.62939453125e-09\n",
      "Epoch: 19 cost time: 2.9382212162017822\n",
      "Epoch: 19, Steps: 48 | Train Loss: 0.3681807  Test Loss: 0.2805442\n",
      "Validation loss decreased (0.280547 --> 0.280544).  Saving model ...\n",
      "Updating learning rate to 3.814697265625e-09\n",
      "Epoch: 20 cost time: 2.874553918838501\n",
      "Epoch: 20, Steps: 48 | Train Loss: 0.3686274  Test Loss: 0.2805432\n",
      "Validation loss decreased (0.280544 --> 0.280543).  Saving model ...\n",
      "Updating learning rate to 1.9073486328125e-09\n",
      "loading model\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy.core.multiarray' has no attribute 'generic'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m#---------反归一化处理----------\u001b[39;00m\n\u001b[0;32m     55\u001b[0m start_time\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 56\u001b[0m preds,trues,masks\u001b[38;5;241m=\u001b[39mexp\u001b[38;5;241m.\u001b[39mtest(setting, test\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;66;03m#测试验证集\u001b[39;00m\n\u001b[0;32m     57\u001b[0m end_time\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     58\u001b[0m trues\u001b[38;5;241m=\u001b[39mget_debatch_data(trues)\n",
      "Cell \u001b[1;32mIn[9], line 217\u001b[0m, in \u001b[0;36mExp_Imputation.test\u001b[1;34m(self, setting, test)\u001b[0m\n\u001b[0;32m    214\u001b[0m             filled \u001b[38;5;241m=\u001b[39m true[\u001b[38;5;241m0\u001b[39m, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    215\u001b[0m             filled \u001b[38;5;241m=\u001b[39m filled \u001b[38;5;241m*\u001b[39m mask[\u001b[38;5;241m0\u001b[39m, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m    216\u001b[0m                      pred[\u001b[38;5;241m0\u001b[39m, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m mask[\u001b[38;5;241m0\u001b[39m, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m--> 217\u001b[0m             visual(true[\u001b[38;5;241m0\u001b[39m, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], filled, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m    219\u001b[0m preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(preds, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    220\u001b[0m trues \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(trues, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\缺失值填充-Transformer\\utils\\tools.py:87\u001b[0m, in \u001b[0;36mvisual\u001b[1;34m(true, preds, name)\u001b[0m\n\u001b[0;32m     85\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(preds, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrediction\u001b[39m\u001b[38;5;124m'\u001b[39m, linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     86\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[1;32m---> 87\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(name, bbox_inches\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\pyplot.py:1134\u001b[0m, in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1131\u001b[0m fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;66;03m# savefig default implementation has no return, so mypy is unhappy\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;66;03m# presumably this is here because subclasses can return?\u001b[39;00m\n\u001b[1;32m-> 1134\u001b[0m res \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[func-returns-value]\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\figure.py:3390\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[1;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[0;32m   3388\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[0;32m   3389\u001b[0m         _recursively_make_axes_transparent(stack, ax)\n\u001b[1;32m-> 3390\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mprint_figure(fname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\backend_bases.py:2164\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2161\u001b[0m     \u001b[38;5;66;03m# we do this instead of `self.figure.draw_without_rendering`\u001b[39;00m\n\u001b[0;32m   2162\u001b[0m     \u001b[38;5;66;03m# so that we can inject the orientation\u001b[39;00m\n\u001b[0;32m   2163\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(renderer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_draw_disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m, nullcontext)():\n\u001b[1;32m-> 2164\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m   2165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[0;32m   2166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m draw(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[0;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\figure.py:3154\u001b[0m, in \u001b[0;36mFigure.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3151\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m   3153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m-> 3154\u001b[0m mimage\u001b[38;5;241m.\u001b[39m_draw_list_compositing_images(\n\u001b[0;32m   3155\u001b[0m     renderer, \u001b[38;5;28mself\u001b[39m, artists, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppressComposite)\n\u001b[0;32m   3157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sfig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubfigs:\n\u001b[0;32m   3158\u001b[0m     sfig\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         a\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\axes\\_base.py:3070\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[0;32m   3068\u001b[0m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, artists_rasterized, renderer)\n\u001b[1;32m-> 3070\u001b[0m mimage\u001b[38;5;241m.\u001b[39m_draw_list_compositing_images(\n\u001b[0;32m   3071\u001b[0m     renderer, \u001b[38;5;28mself\u001b[39m, artists, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39msuppressComposite)\n\u001b[0;32m   3073\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         a\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\axis.py:1388\u001b[0m, in \u001b[0;36mAxis.draw\u001b[1;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1385\u001b[0m renderer\u001b[38;5;241m.\u001b[39mopen_group(\u001b[38;5;18m__name__\u001b[39m, gid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_gid())\n\u001b[0;32m   1387\u001b[0m ticks_to_draw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_ticks()\n\u001b[1;32m-> 1388\u001b[0m tlb1, tlb2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ticklabel_bboxes(ticks_to_draw, renderer)\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks_to_draw:\n\u001b[0;32m   1391\u001b[0m     tick\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\axis.py:1315\u001b[0m, in \u001b[0;36mAxis._get_ticklabel_bboxes\u001b[1;34m(self, ticks, renderer)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1314\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[1;32m-> 1315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ([tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1316\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_visible()],\n\u001b[0;32m   1317\u001b[0m         [tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1318\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_visible()])\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\text.py:956\u001b[0m, in \u001b[0;36mText.get_window_extent\u001b[1;34m(self, renderer, dpi)\u001b[0m\n\u001b[0;32m    951\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    952\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get window extent of text w/o renderer. You likely \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwant to call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure.draw_without_rendering()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[1;32m--> 956\u001b[0m     bbox, info, descent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_layout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_renderer)\n\u001b[0;32m    957\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_unitless_position()\n\u001b[0;32m    958\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_transform()\u001b[38;5;241m.\u001b[39mtransform((x, y))\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\text.py:442\u001b[0m, in \u001b[0;36mText._get_layout\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    440\u001b[0m corners_rotated \u001b[38;5;241m=\u001b[39m M\u001b[38;5;241m.\u001b[39mtransform(corners_horiz)\n\u001b[0;32m    441\u001b[0m \u001b[38;5;66;03m# compute the bounds of the rotated box\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m xmin \u001b[38;5;241m=\u001b[39m corners_rotated[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\n\u001b[0;32m    443\u001b[0m xmax \u001b[38;5;241m=\u001b[39m corners_rotated[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m    444\u001b[0m ymin \u001b[38;5;241m=\u001b[39m corners_rotated[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\numpy\\_core\\_methods.py:14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m umath \u001b[38;5;28;01mas\u001b[39;00m um\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultiarray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m asanyarray\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m numerictypes \u001b[38;5;28;01mas\u001b[39;00m nt\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _exceptions\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ufunc_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _no_nep50_warning\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\numpy\\_core\\numerictypes.py:102\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# we don't need all these imports, but we need to keep them for compatibility\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# for users using np._core.numerictypes.UPPER_TABLE\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_string_helpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     99\u001b[0m     english_lower, english_upper, english_capitalize, LOWER_TABLE, UPPER_TABLE\n\u001b[0;32m    100\u001b[0m )\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_type_aliases\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    103\u001b[0m     sctypeDict, allTypes, sctypes\n\u001b[0;32m    104\u001b[0m )\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dtype\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _kind_name\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# we don't export these for import *, but we do want them accessible\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# as numerictypes.bool, etc.\u001b[39;00m\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\numpy\\_core\\_type_aliases.py:38\u001b[0m\n\u001b[0;32m     31\u001b[0m _abstract_type_names \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneric\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minteger\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minexact\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloating\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflexible\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcharacter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplexfloating\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsignedinteger\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignedinteger\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m }\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _abstract_type_name \u001b[38;5;129;01min\u001b[39;00m _abstract_type_names:\n\u001b[1;32m---> 38\u001b[0m     allTypes[_abstract_type_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(ma, _abstract_type_name)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m typeinfo\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNPY_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m v \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m c_names_dict:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy.core.multiarray' has no attribute 'generic'"
     ]
    }
   ],
   "source": [
    "windows_size=96\n",
    "batch_size=128\n",
    "\n",
    "#-----------------归一化处理-----------------\n",
    "scolar=StandardScaler()\n",
    "scolar.fit(train_data)\n",
    "train_miss_normal=scolar.transform(train_miss)\n",
    "train_data_normal=scolar.transform(train_data)\n",
    "test_miss_normal=scolar.transform(test_miss)\n",
    "test_data_normal=scolar.transform(test_data)\n",
    "\n",
    "#--------------数据打包--------------------\n",
    "train_dataset=Dataset_me(train_miss_normal,train_data_normal,train_stamp,windows_size=windows_size)\n",
    "test_dataset=Dataset_me(test_miss_normal,test_data_normal,test_stamp,windows_size=windows_size)\n",
    "\n",
    "train_loader=DataLoader(train_dataset,batch_size=batch_size)\n",
    "test_loader=DataLoader(test_dataset,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "#---------------------定义参数--------------------\n",
    "parser = argparse.ArgumentParser(description='Transformer')\n",
    "parser.add_argument('--enc_in', type=int, default=7, help='encoder input size')\n",
    "parser.add_argument('--d_model', type=int, default=256, help='dimension of model')\n",
    "parser.add_argument('--embed', type=str, default='timeF',help='time features encoding, options:[timeF, fixed, learned]')\n",
    "\n",
    "parser.add_argument('--freq', type=str, default='h',\n",
    "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "parser.add_argument('--dropout', type=float, default=0.1, help='dropout')\n",
    "\n",
    "parser.add_argument('--factor', type=int, default=1, help='attn factor')\n",
    "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in ecoder')\n",
    "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
    "parser.add_argument('--d_ff', type=int, default=256, help='dimension of fcn')\n",
    "parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
    "parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')\n",
    "parser.add_argument('--c_out', type=int, default=7, help='output size')\n",
    "parser.add_argument('--train_epochs', type=int, default=20, help='output train_epochs')\n",
    "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.001, help='learning_rate')\n",
    "parser.add_argument('--lradj', type=str, default='type1', help='adjust learning rate')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "args.enc_in=train_data_normal.shape[1]#更新参数，输入数据的特征维度数\n",
    "args.c_out=train_data_normal.shape[1]#更新参数，输入数据的特征维度数\n",
    "\n",
    "device=torch.device('cuda' if args.use_gpu else 'cpu')\n",
    "\n",
    "#--------------------定义模型并测试-----------------\n",
    "setting = 'transformer'\n",
    "model=Model(args)\n",
    "exp=Exp_Imputation(args,train_loader,test_loader,model)\n",
    "exp.train(setting)#训练\n",
    "\n",
    "#---------反归一化处理----------\n",
    "start_time=time.time()\n",
    "preds,trues,masks=exp.test(setting, test=1)#测试验证集\n",
    "end_time=time.time()\n",
    "trues=get_debatch_data(trues)\n",
    "preds=get_debatch_data(preds)\n",
    "masks=get_debatch_data(masks)\n",
    "\n",
    "preds_anti=scolar.inverse_transform(preds)\n",
    "trues_anti=scolar.inverse_transform(trues)\n",
    "\n",
    "# 计算评估指标\n",
    "tran_result=get_result(trues_anti[masks == 0], preds_anti[masks == 0])+[end_time-start_time]\n",
    "result_dict['Transformer']=tran_result\n",
    "predict_dict['Transformer']={'true':trues_anti[masks == 0],'pred':preds_anti[masks == 0]}\n",
    "\n",
    "trues_anti_df=pd.DataFrame(trues_anti,index=test_miss.index,columns=test_miss.columns)\n",
    "preds_anti_df=pd.DataFrame(preds_anti,index=test_miss.index,columns=test_miss.columns)\n",
    "true_mask_df=trues_anti_df.mask(masks==1)\n",
    "pred_mask_df=preds_anti_df.mask(masks==1)\n",
    "mask_pred_dict['Transformer']={'true':true_mask_df,'pred':pred_mask_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4d38729-2d83-4687-968f-fafb3d04deb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy.core.multiarray' has no attribute 'generic'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m             filled \u001b[38;5;241m=\u001b[39m true[\u001b[38;5;241m0\u001b[39m, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     35\u001b[0m             filled \u001b[38;5;241m=\u001b[39m filled \u001b[38;5;241m*\u001b[39m mask[\u001b[38;5;241m0\u001b[39m, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m     36\u001b[0m                      pred[\u001b[38;5;241m0\u001b[39m, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m mask[\u001b[38;5;241m0\u001b[39m, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 37\u001b[0m             visual(true[\u001b[38;5;241m0\u001b[39m, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], filled, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     39\u001b[0m preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(preds, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     40\u001b[0m trues \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(trues, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\缺失值填充-Transformer\\utils\\tools.py:87\u001b[0m, in \u001b[0;36mvisual\u001b[1;34m(true, preds, name)\u001b[0m\n\u001b[0;32m     85\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(preds, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrediction\u001b[39m\u001b[38;5;124m'\u001b[39m, linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     86\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[1;32m---> 87\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(name, bbox_inches\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\pyplot.py:1134\u001b[0m, in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1131\u001b[0m fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;66;03m# savefig default implementation has no return, so mypy is unhappy\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;66;03m# presumably this is here because subclasses can return?\u001b[39;00m\n\u001b[1;32m-> 1134\u001b[0m res \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[func-returns-value]\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\figure.py:3390\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[1;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[0;32m   3388\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[0;32m   3389\u001b[0m         _recursively_make_axes_transparent(stack, ax)\n\u001b[1;32m-> 3390\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mprint_figure(fname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\backend_bases.py:2164\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2161\u001b[0m     \u001b[38;5;66;03m# we do this instead of `self.figure.draw_without_rendering`\u001b[39;00m\n\u001b[0;32m   2162\u001b[0m     \u001b[38;5;66;03m# so that we can inject the orientation\u001b[39;00m\n\u001b[0;32m   2163\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(renderer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_draw_disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m, nullcontext)():\n\u001b[1;32m-> 2164\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m   2165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[0;32m   2166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m draw(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[0;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\figure.py:3154\u001b[0m, in \u001b[0;36mFigure.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3151\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m   3153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m-> 3154\u001b[0m mimage\u001b[38;5;241m.\u001b[39m_draw_list_compositing_images(\n\u001b[0;32m   3155\u001b[0m     renderer, \u001b[38;5;28mself\u001b[39m, artists, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppressComposite)\n\u001b[0;32m   3157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sfig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubfigs:\n\u001b[0;32m   3158\u001b[0m     sfig\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         a\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\axes\\_base.py:3070\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[0;32m   3068\u001b[0m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, artists_rasterized, renderer)\n\u001b[1;32m-> 3070\u001b[0m mimage\u001b[38;5;241m.\u001b[39m_draw_list_compositing_images(\n\u001b[0;32m   3071\u001b[0m     renderer, \u001b[38;5;28mself\u001b[39m, artists, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39msuppressComposite)\n\u001b[0;32m   3073\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         a\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\axis.py:1388\u001b[0m, in \u001b[0;36mAxis.draw\u001b[1;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1385\u001b[0m renderer\u001b[38;5;241m.\u001b[39mopen_group(\u001b[38;5;18m__name__\u001b[39m, gid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_gid())\n\u001b[0;32m   1387\u001b[0m ticks_to_draw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_ticks()\n\u001b[1;32m-> 1388\u001b[0m tlb1, tlb2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ticklabel_bboxes(ticks_to_draw, renderer)\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks_to_draw:\n\u001b[0;32m   1391\u001b[0m     tick\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\axis.py:1315\u001b[0m, in \u001b[0;36mAxis._get_ticklabel_bboxes\u001b[1;34m(self, ticks, renderer)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1314\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[1;32m-> 1315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ([tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1316\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_visible()],\n\u001b[0;32m   1317\u001b[0m         [tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1318\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_visible()])\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\text.py:956\u001b[0m, in \u001b[0;36mText.get_window_extent\u001b[1;34m(self, renderer, dpi)\u001b[0m\n\u001b[0;32m    951\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    952\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get window extent of text w/o renderer. You likely \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwant to call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure.draw_without_rendering()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[1;32m--> 956\u001b[0m     bbox, info, descent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_layout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_renderer)\n\u001b[0;32m    957\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_unitless_position()\n\u001b[0;32m    958\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_transform()\u001b[38;5;241m.\u001b[39mtransform((x, y))\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\matplotlib\\text.py:442\u001b[0m, in \u001b[0;36mText._get_layout\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    440\u001b[0m corners_rotated \u001b[38;5;241m=\u001b[39m M\u001b[38;5;241m.\u001b[39mtransform(corners_horiz)\n\u001b[0;32m    441\u001b[0m \u001b[38;5;66;03m# compute the bounds of the rotated box\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m xmin \u001b[38;5;241m=\u001b[39m corners_rotated[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\n\u001b[0;32m    443\u001b[0m xmax \u001b[38;5;241m=\u001b[39m corners_rotated[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m    444\u001b[0m ymin \u001b[38;5;241m=\u001b[39m corners_rotated[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\numpy\\_core\\_methods.py:14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m umath \u001b[38;5;28;01mas\u001b[39;00m um\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultiarray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m asanyarray\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m numerictypes \u001b[38;5;28;01mas\u001b[39;00m nt\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _exceptions\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ufunc_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _no_nep50_warning\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\numpy\\_core\\numerictypes.py:102\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# we don't need all these imports, but we need to keep them for compatibility\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# for users using np._core.numerictypes.UPPER_TABLE\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_string_helpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     99\u001b[0m     english_lower, english_upper, english_capitalize, LOWER_TABLE, UPPER_TABLE\n\u001b[0;32m    100\u001b[0m )\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_type_aliases\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    103\u001b[0m     sctypeDict, allTypes, sctypes\n\u001b[0;32m    104\u001b[0m )\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dtype\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _kind_name\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# we don't export these for import *, but we do want them accessible\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# as numerictypes.bool, etc.\u001b[39;00m\n",
      "File \u001b[1;32mE:\\anaconda2\\envs\\try1\\Lib\\site-packages\\numpy\\_core\\_type_aliases.py:38\u001b[0m\n\u001b[0;32m     31\u001b[0m _abstract_type_names \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneric\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minteger\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minexact\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloating\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflexible\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcharacter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplexfloating\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsignedinteger\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignedinteger\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m }\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _abstract_type_name \u001b[38;5;129;01min\u001b[39;00m _abstract_type_names:\n\u001b[1;32m---> 38\u001b[0m     allTypes[_abstract_type_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(ma, _abstract_type_name)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m typeinfo\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNPY_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m v \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m c_names_dict:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy.core.multiarray' has no attribute 'generic'"
     ]
    }
   ],
   "source": [
    "        if 1:\n",
    "            print('loading model')\n",
    "            exp.model.load_state_dict(torch.load(exp.best_model_path))\n",
    "            \n",
    "        preds = []\n",
    "        trues = []\n",
    "        masks = []\n",
    "        \n",
    "        folder_path = './test_results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "            \n",
    "        exp.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x_mask, batch_x, batch_x_mark) in enumerate(test_loader):\n",
    "                batch_x=batch_x.float().to(device)\n",
    "                batch_x_mark = batch_x_mark.float().to(device)\n",
    "                mask=(batch_x_mask.isnan()==False).int().to(device)\n",
    "                batch_x_mask[batch_x_mask.isnan()]=0.0#---------------用0填充缺失值----\n",
    "                batch_x_mask=batch_x_mask.to(torch.float32).to(device)\n",
    "                \n",
    "                outputs = exp.model(batch_x_mask, batch_x_mark, None, None, mask)\n",
    "                \n",
    "                outputs = np.array(outputs.detach().cpu().tolist())\n",
    "                pred = outputs\n",
    "                true = np.array(batch_x.detach().cpu().tolist())\n",
    "                # print(true)\n",
    "                preds.append(pred)\n",
    "                trues.append(true)\n",
    "                mask=np.array(mask.detach().cpu().tolist())\n",
    "                masks.append(mask)\n",
    "                \n",
    "                if i % 20 == 0:\n",
    "                    filled = true[0, :, -1].copy()\n",
    "                    filled = filled * mask[0, :, -1] + \\\n",
    "                             pred[0, :, -1] * (1 - mask[0, :, -1])\n",
    "                    visual(true[0, :, -1], filled, os.path.join(folder_path, str(i) + '.pdf'))\n",
    "\n",
    "        preds = np.concatenate(preds, 0)\n",
    "        trues = np.concatenate(trues, 0)\n",
    "        masks = np.concatenate(masks, 0)\n",
    "        print('test shape:', preds.shape, trues.shape)\n",
    "\n",
    "        # result save\n",
    "        folder_path = './results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        mae, mse, rmse, mape, mspe = metric(preds[masks == 0], trues[masks == 0])\n",
    "\n",
    "        print('mse:{}, mae:{}'.format(mse, mae))\n",
    "        f = open(\"result_imputation.txt\", 'a')\n",
    "        f.write(setting + \"  \\n\")\n",
    "        f.write('mse:{}, mae:{}'.format(mse, mae))\n",
    "        f.write('\\n')\n",
    "        f.write('\\n')\n",
    "        f.close()\n",
    "\n",
    "        np.save(folder_path + 'metrics.npy', np.array([mae, mse, rmse, mape, mspe]))\n",
    "        np.save(folder_path + 'pred.npy', preds)\n",
    "        np.save(folder_path + 'true.npy', trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4edfb1ef-d7f1-4134-9c5a-5df6a21d1830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.98985839, -1.04402041, -1.07619405, ...,  1.2530396 ,\n",
       "          0.89157671,  0.05124401],\n",
       "        [-1.25333214, -1.33691347, -1.24807525, ...,  0.81658381,\n",
       "          0.3181479 , -0.27584717],\n",
       "        [-0.52877933, -0.50573051, -0.49097961, ...,  0.15944654,\n",
       "         -0.09434149, -0.39960593],\n",
       "        ...,\n",
       "        [ 0.16090201,  0.19483794,  0.16789822, ...,  0.68367016,\n",
       "          0.48492375,  0.00261005],\n",
       "        [-0.61402082, -0.5809328 , -0.52371889, ...,  0.67175281,\n",
       "          0.43706506, -0.03945175],\n",
       "        [-0.24980709, -0.23262756, -0.15540209, ...,  0.53729695,\n",
       "          0.31347874, -0.10739774]],\n",
       "\n",
       "       [[-1.25333214, -1.33691347, -1.24807525, ...,  0.81658381,\n",
       "          0.3181479 , -0.27584717],\n",
       "        [-0.52877933, -0.50573051, -0.49097961, ...,  0.15944654,\n",
       "         -0.09434149, -0.39960593],\n",
       "        [-0.35829628, -0.35136798, -0.28226677, ..., -0.22779757,\n",
       "         -0.5256533 , -0.67482764],\n",
       "        ...,\n",
       "        [-0.61402082, -0.5809328 , -0.52371889, ...,  0.67175281,\n",
       "          0.43706506, -0.03945175],\n",
       "        [-0.24980709, -0.23262756, -0.15540209, ...,  0.53729695,\n",
       "          0.31347874, -0.10739774],\n",
       "        [-0.42803934, -0.39886415, -0.3436529 , ...,  0.58791071,\n",
       "          0.36965436, -0.08656906]],\n",
       "\n",
       "       [[-0.52877933, -0.50573051, -0.49097961, ...,  0.15944654,\n",
       "         -0.09434149, -0.39960593],\n",
       "        [-0.35829628, -0.35136798, -0.28226677, ..., -0.22779757,\n",
       "         -0.5256533 , -0.67482764],\n",
       "        [-0.04832716, -0.01493679,  0.07377281, ..., -0.30897582,\n",
       "         -0.63566995, -0.70414954],\n",
       "        ...,\n",
       "        [-0.24980709, -0.23262756, -0.15540209, ...,  0.53729695,\n",
       "          0.31347874, -0.10739774],\n",
       "        [-0.42803934, -0.39886415, -0.3436529 , ...,  0.58791071,\n",
       "          0.36965436, -0.08656906],\n",
       "        [-0.27692938, -0.24450159, -0.21269581, ...,  0.66249937,\n",
       "          0.44188011, -0.01033204]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.04431403,  1.05768502,  1.09687507, ..., -0.89082342,\n",
       "         -1.12228191, -1.02112973],\n",
       "        [ 1.1024332 ,  1.04976892,  1.055951  , ..., -0.86320317,\n",
       "         -1.07427728, -0.95530701],\n",
       "        [ 0.61423182,  0.51147908,  0.50756818, ..., -0.82254392,\n",
       "         -1.0253973 , -0.89362985],\n",
       "        ...,\n",
       "        [-1.09834754, -1.15484476, -1.14576507, ..., -0.86474544,\n",
       "         -0.9447087 , -0.71911383],\n",
       "        [-0.58302391, -0.67988312, -0.70787728, ..., -0.99569619,\n",
       "         -1.15277731, -0.98321342],\n",
       "        [-0.54815239, -0.56510073, -0.60965949, ..., -0.97957271,\n",
       "         -1.24163687, -1.11586988]],\n",
       "\n",
       "       [[ 1.1024332 ,  1.04976892,  1.055951  , ..., -0.86320317,\n",
       "         -1.07427728, -0.95530701],\n",
       "        [ 0.61423182,  0.51147908,  0.50756818, ..., -0.82254392,\n",
       "         -1.0253973 , -0.89362985],\n",
       "        [ 0.88158023,  0.85186827,  0.8636077 , ..., -0.72173709,\n",
       "         -0.96747077, -0.89130431],\n",
       "        ...,\n",
       "        [-0.58302391, -0.67988312, -0.70787728, ..., -0.99569619,\n",
       "         -1.15277731, -0.98321342],\n",
       "        [-0.54815239, -0.56510073, -0.60965949, ..., -0.97957271,\n",
       "         -1.24163687, -1.11586988],\n",
       "        [-0.50165701, -0.45427632, -0.50734925, ..., -1.08234239,\n",
       "         -1.32597315, -1.18401802]],\n",
       "\n",
       "       [[ 0.61423182,  0.51147908,  0.50756818, ..., -0.82254392,\n",
       "         -1.0253973 , -0.89362985],\n",
       "        [ 0.88158023,  0.85186827,  0.8636077 , ..., -0.72173709,\n",
       "         -0.96747077, -0.89130431],\n",
       "        [ 0.76921642,  0.7489599 ,  0.76948231, ..., -0.81301004,\n",
       "         -1.05195296, -0.94519603],\n",
       "        ...,\n",
       "        [-0.54815239, -0.56510073, -0.60965949, ..., -0.97957271,\n",
       "         -1.24163687, -1.11586988],\n",
       "        [-0.50165701, -0.45427632, -0.50734925, ..., -1.08234239,\n",
       "         -1.32597315, -1.18401802],\n",
       "        [-0.33504859, -0.28408173, -0.31500605, ..., -1.07098579,\n",
       "         -1.33210146, -1.19776905]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f699cea-3a27-4852-ac3e-d0637f812826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 0,  ..., 1, 1, 0],\n",
       "         [1, 0, 1,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 1, 1, 0],\n",
       "         ...,\n",
       "         [1, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 1, 1,  ..., 0, 0, 1],\n",
       "         [0, 0, 0,  ..., 0, 1, 0]],\n",
       "\n",
       "        [[1, 0, 1,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 1, 1, 0],\n",
       "         [0, 0, 0,  ..., 1, 1, 0],\n",
       "         ...,\n",
       "         [0, 1, 1,  ..., 0, 0, 1],\n",
       "         [0, 0, 0,  ..., 0, 1, 0],\n",
       "         [1, 1, 0,  ..., 1, 0, 1]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 1, 1, 0],\n",
       "         [0, 0, 0,  ..., 1, 1, 0],\n",
       "         [1, 0, 0,  ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 1, 0],\n",
       "         [1, 1, 0,  ..., 1, 0, 1],\n",
       "         [1, 1, 1,  ..., 1, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 1, 0],\n",
       "         [1, 0, 1,  ..., 1, 1, 0],\n",
       "         [1, 0, 0,  ..., 0, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 0, 0],\n",
       "         [0, 1, 1,  ..., 0, 1, 1]],\n",
       "\n",
       "        [[1, 0, 1,  ..., 1, 1, 0],\n",
       "         [1, 0, 0,  ..., 0, 1, 1],\n",
       "         [1, 1, 1,  ..., 0, 1, 1],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 1, 0, 0],\n",
       "         [0, 1, 1,  ..., 0, 1, 1],\n",
       "         [1, 1, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[1, 0, 0,  ..., 0, 1, 1],\n",
       "         [1, 1, 1,  ..., 0, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 0, 1],\n",
       "         ...,\n",
       "         [0, 1, 1,  ..., 0, 1, 1],\n",
       "         [1, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 1, 0, 0]]], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88807862",
   "metadata": {},
   "source": [
    "# Autoformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d99b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from layers.Embed import DataEmbedding, DataEmbedding_wo_pos\n",
    "from layers.AutoCorrelation import AutoCorrelation, AutoCorrelationLayer\n",
    "from layers.Autoformer_EncDec import Encoder, Decoder, EncoderLayer, DecoderLayer, my_Layernorm, series_decomp\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class AutoformerNet(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(AutoformerNet, self).__init__()\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.output_attention = configs.output_attention\n",
    "\n",
    "        # Embedding\n",
    "        self.enc_embedding = DataEmbedding_wo_pos(configs.enc_in, configs.d_model, \n",
    "                                                  configs.embed, configs.freq,\n",
    "                                                  configs.dropout)\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AutoCorrelationLayer(\n",
    "                        AutoCorrelation(False, configs.factor, attention_dropout=configs.dropout,\n",
    "                                        output_attention=configs.output_attention),\n",
    "                        configs.d_model, configs.n_heads),\n",
    "                    configs.d_model,\n",
    "                    configs.d_ff,\n",
    "                    moving_avg=configs.moving_avg,\n",
    "                    dropout=configs.dropout,\n",
    "                    activation=configs.activation\n",
    "                ) for l in range(configs.e_layers)\n",
    "            ],\n",
    "            norm_layer=my_Layernorm(configs.d_model)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.projection = nn.Linear(\n",
    "                configs.d_model, configs.c_out, bias=True)\n",
    "\n",
    "\n",
    "    def imputation(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask):\n",
    "        # enc\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
    "        enc_out, attns = self.encoder(enc_out, attn_mask=None)\n",
    "        # final\n",
    "        dec_out = self.projection(enc_out)\n",
    "        return dec_out\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask=None):\n",
    "        dec_out = self.imputation(\n",
    "                x_enc, x_mark_enc, x_dec, x_mark_dec, mask)\n",
    "        return dec_out  # [B, L, D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9b47dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "windows_size=96\n",
    "batch_size=128\n",
    "\n",
    "#-----------------归一化处理-----------------\n",
    "scolar=StandardScaler()\n",
    "scolar.fit(train_data)\n",
    "train_miss_normal=scolar.transform(train_miss)\n",
    "train_data_normal=scolar.transform(train_data)\n",
    "test_miss_normal=scolar.transform(test_miss)\n",
    "test_data_normal=scolar.transform(test_data)\n",
    "\n",
    "#--------------数据打包--------------------\n",
    "train_dataset=Dataset_me(train_miss_normal,train_data_normal,train_stamp,windows_size=windows_size)\n",
    "test_dataset=Dataset_me(test_miss_normal,test_data_normal,test_stamp,windows_size=windows_size)\n",
    "\n",
    "train_loader=DataLoader(train_dataset,batch_size=batch_size)\n",
    "test_loader=DataLoader(test_dataset,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "#---------------------定义参数--------------------\n",
    "parser = argparse.ArgumentParser(description='AutoformerNet')\n",
    "parser.add_argument('--enc_in', type=int, default=7, help='encoder input size')\n",
    "parser.add_argument('--d_model', type=int, default=256, help='dimension of model')\n",
    "parser.add_argument('--embed', type=str, default='timeF',help='time features encoding, options:[timeF, fixed, learned]')\n",
    "\n",
    "parser.add_argument('--freq', type=str, default='h',\n",
    "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "parser.add_argument('--dropout', type=float, default=0.1, help='dropout')\n",
    "\n",
    "parser.add_argument('--factor', type=int, default=1, help='attn factor')\n",
    "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in ecoder')\n",
    "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
    "parser.add_argument('--d_ff', type=int, default=512, help='dimension of fcn')\n",
    "parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
    "parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')\n",
    "parser.add_argument('--c_out', type=int, default=7, help='output size')\n",
    "parser.add_argument('--train_epochs', type=int, default=20, help='output train_epochs')\n",
    "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.001, help='learning_rate')\n",
    "parser.add_argument('--lradj', type=str, default='type1', help='adjust learning rate')\n",
    "parser.add_argument('--pred_len', type=int, default=0, help='prediction sequence length')\n",
    "parser.add_argument('--top_k', type=int, default=5, help='for TimesBlock')\n",
    "parser.add_argument('--num_kernels', type=int, default=3, help='for Inception')\n",
    "parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "args.enc_in=train_data_normal.shape[1]#更新参数，输入数据的特征维度数\n",
    "args.c_out=train_data_normal.shape[1]#更新参数，输出数据的特征维度数\n",
    "args.seq_len=windows_size#输入数据的序列长度\n",
    "\n",
    "\n",
    "device=torch.device('cuda' if args.use_gpu else 'cpu')\n",
    "\n",
    "#--------------------定义模型并测试-----------------\n",
    "setting = 'AutoformerNet'\n",
    "model=AutoformerNet(args)\n",
    "exp=Exp_Imputation(args,train_loader,test_loader,model)\n",
    "exp.train(setting)#训练\n",
    "\n",
    "#---------反归一化处理----------\n",
    "start_time=time.time()\n",
    "preds,trues,masks=exp.test(setting, test=1)#测试验证集\n",
    "end_time=time.time()\n",
    "trues=get_debatch_data(trues)\n",
    "preds=get_debatch_data(preds)\n",
    "masks=get_debatch_data(masks)\n",
    "\n",
    "preds_anti=scolar.inverse_transform(preds)\n",
    "trues_anti=scolar.inverse_transform(trues)\n",
    "\n",
    "# 计算评估指标\n",
    "AutoformerNet_result=get_result(trues_anti[masks == 0], preds_anti[masks == 0])+[end_time-start_time]\n",
    "result_dict['AutoformerNet']=AutoformerNet_result\n",
    "predict_dict['AutoformerNet']={'true':trues_anti[masks == 0],'pred':preds_anti[masks == 0]}\n",
    "\n",
    "trues_anti_df=pd.DataFrame(trues_anti,index=test_miss.index,columns=test_miss.columns)\n",
    "preds_anti_df=pd.DataFrame(preds_anti,index=test_miss.index,columns=test_miss.columns)\n",
    "true_mask_df=trues_anti_df.mask(masks==1)\n",
    "pred_mask_df=preds_anti_df.mask(masks==1)\n",
    "mask_pred_dict['AutoformerNet']={'true':true_mask_df,'pred':pred_mask_df}\n",
    "\n",
    "AutoformerNet_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d3438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------结果保存----------------------\n",
    "result_dict_df=pd.DataFrame(result_dict,index=['mae','mse','mape','r2','time']).T\n",
    "result_dict_df.to_csv('./所有模型的性能指标.csv',encoding='utf_8_sig')\n",
    "result_dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a25d06e-0e1a-4f60-b4e3-025cf31686a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del plt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44e3d50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_pred_true_df={}\n",
    "for name,values in predict_dict.items():\n",
    "    new_pred_true_df[name]=values['pred']\n",
    "new_pred_true_df['True']=values['true']\n",
    "new_pred_true_df=pd.DataFrame(new_pred_true_df)\n",
    "new_pred_true_df.to_csv('./所有模型的预测.csv',encoding='utf_8_sig')\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "new_pred_true_df[:100].plot(figsize=(16,8))\n",
    "plt.xlabel('data id')\n",
    "plt.ylabel('value')\n",
    "plt.savefig('./所有模型的部分预测结果展示.png',dpi=400)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#----------------展示某一列的预测效果--------------\n",
    "columns_id=0#想要展示的第N列\n",
    "columnd_data={}\n",
    "for name,value in mask_pred_dict.items():\n",
    "    true=value['true']\n",
    "    pred=value['pred']\n",
    "    columnd_data[name]=pred[test_miss.columns[columns_id]]\n",
    "columnd_data['True']=true[test_miss.columns[columns_id]]\n",
    "columnd_data['Raw']=test_data[test_miss.columns[columns_id]]\n",
    "columnd_data_df=pd.DataFrame(columnd_data)[:100]#取前100行进行可视化\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(columnd_data_df['Raw'],label='Raw')\n",
    "plt.plot(columnd_data_df['True'],'^',label='Mask')\n",
    "for column in columnd_data_df.columns:\n",
    "    if column in ['Raw','True']:\n",
    "        continue\n",
    "    plt.plot(columnd_data_df[column],'*',label=column)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Values')\n",
    "plt.savefig('./所有模型的某一列预测结果展示.png',dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614a1ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf5e3fb-ece8-48e1-8891-e0396e71040d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2119065e-b64f-4c61-a862-7bd7f6fde16c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
